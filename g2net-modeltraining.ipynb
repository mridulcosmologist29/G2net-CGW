{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cp /kaggle/input/model-trainingdata/df_final-2023_01_01_10_42_1672569751 .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ls -l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#dbfile = open('df_final-2023_01_01_10_42_1672569751', 'rb') \n#dataset = pickle.load(dbfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dbfile.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.linear_model import Perceptron","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracting signal/noise label feature\n#y=dataset['y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#temp_dataset=dataset[:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing y from dataset\n#x=temp_dataset.drop(['y'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# perceptron model\n#ppn = Perceptron(eta0=0.1, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = temp dataset \n# y = label \n#ppn.fit(x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!touch perceptron_ppn-`date +\"%Y_%m_%d_%I_%M_%s\"`","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code for saving the perceptron model ppn\n#model_file = open('perceptron_ppn-2023_01_01_12_30_1672576249','ab')\n#pickle.dump(ppn,model_file)     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ls -l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data Generation","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/PyFstat/PyFstat@python37","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimport pyfstat\nfrom pyfstat.utils import get_sft_as_arrays\n\n# Local module to simplify plotting\n#import tutorial_utils\n\nlogger = pyfstat.set_up_logger(label=\"0_generating_noise\", log_level=\"INFO\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NOISE\n\n# Setup Writer\nwriter_kwargs = {\n    \"label\": \"single_detector_gaussian_noise\",\n    \"outdir\": \"PyFstat_example_data\",\n    \"tstart\": 1238166018,  # Starting time of the observation [GPS time]\n    \"duration\": 365 * 86400,  # Duration [seconds]\n    \"detectors\": \"H1\",  # Detector to simulate, in this case LIGO Hanford\n    \"F0\": 100.0,  # Central frequency of the band to be generated [Hz]\n    \"Band\": 1.0,  # Frequency band-width around F0 [Hz]\n    \"sqrtSX\": 1e-23,  # Single-sided Amplitude Spectral Density of the noise\n    \"Tsft\": 1800,  # Fourier transform time duration\n    \"SFTWindowType\": \"tukey\",  # Window function to compute short Fourier transforms\n    \"SFTWindowBeta\": 0.01,  # Parameter associated to the window function\n}\nwriter = pyfstat.Writer(**writer_kwargs)\n\n# Create SFTs\nwriter.make_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# noise fourier data creation\n\nfrequency_noise, timestamps_noise, fourier_data_noise = get_sft_as_arrays(writer.sftfilepath)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SIGNAL + NOISE\n\nwriter_kwargs = {\n    \"label\": \"single_detector_gaussian_noise\",\n    \"outdir\": \"PyFstat_example_data\",\n    \"tstart\": 1238166018,\n    \"duration\": 365 * 86400,\n    \"detectors\": \"H1\",\n    \"Band\": 1.0,  # Frequency band-width around F0 [Hz]\n    \"sqrtSX\": 1e-23,\n    \"Tsft\": 1800,\n    \"SFTWindowType\": \"tukey\",\n    \"SFTWindowBeta\": 0.01,\n}\n\nsignal_parameters = {\n    \"F0\": 100.0,\n    \"F1\": -1e-9,\n    \"Alpha\": 0.0,\n    \"Delta\": 0.0,\n    \"h0\": 1e-22,\n    \"cosi\": 1,\n    \"psi\": 0.0,\n    \"phi\": 0.0,\n    \"tref\": writer_kwargs[\"tstart\"],\n}\n\nwriter = pyfstat.Writer(**writer_kwargs, **signal_parameters)\nwriter.make_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Signal + noise fourier data creation\n\nfrequency_signal, timestamps_signal, fourier_data_signal = get_sft_as_arrays(writer.sftfilepath)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# complex SFFT to real data  $ flattening of array\n\n      # signal - \nsignal_flatten=np.absolute(fourier_data_signal['H1']).flatten()\nsignal_matrix=np.absolute(fourier_data_signal['H1'])\n\n     # noise - \nnoise_flatten=np.absolute(fourier_data_noise['H1']).flatten()\nnoise_matrix=np.absolute(fourier_data_noise['H1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fourier real matrix conversion to power in db\n\n    # signal - \n    \nsignal_power = 10 * np.log10(signal_matrix)\n\n    \n    # noise -\n    \nnoise_power = 10 * np.log10(noise_matrix)\n\n#signal_power,noise_power","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting frequency scale with power of signal + noise data\n\nplt.figure()\nplt.plot(frequency_signal, signal_power, color='black')\nplt.xlabel('Signal Frequency (kHz)')\nplt.ylabel('Signal power (dB)')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting frequency scale with power of noise data\n\nplt.figure()\nplt.plot(frequency_noise, noise_power, color='black')\nplt.xlabel('Noise Frequency (kHz)')\nplt.ylabel('Noise power (dB)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  creating the dict/map corresponding to frequency with max of noise powerarray matrix with (len = 17520) \n\nnoisemax={}\nnoisemaxfreq={}\nfor x in range(0,len(frequency_noise)):\n    noisemax[frequency_noise[x]]=noise_power[x].max()\nfor a in noisemax:\n    if noisemax[a]>-210:\n        noisemaxfreq[a]=noisemax[a]\nnoisemaxfreqKeys=noisemaxfreq.keys()   \nnoisemaxfreqKeyslist=list(noisemaxfreqKeys)\nlen(noisemaxfreqKeyslist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  creating the dict/map corresponding to frequency with max of signal powerarray matrix with (len = 17520) \n\nsignalmax={}\nsignalmaxfreq={}\nfor x in range(0,len(frequency_signal)):\n    signalmax[frequency_signal[x]]=signal_power[x].max()\nfor a in signalmax:\n    if signalmax[a]>-210:\n        signalmaxfreq[a]=signalmax[a]\nsignalmaxfreqKeys=signalmaxfreq.keys()\nsignalmaxfreqKeyslist=list(signalmaxfreqKeys)\nlen(signalmaxfreqKeyslist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating 17000+ features and Loading Extracted features from external file  additional_noise+additional_signal","metadata":{}},{"cell_type":"code","source":"df1 = pd.DataFrame(fourier_data_noise['H1'].imag)\ndfx1=df1.applymap(np.absolute)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(fourier_data_signal['H1'].imag)\ndfx2=df2.applymap(np.absolute)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cp /kaggle/input/finalfreqfeature/finaladditionalfeaturefreq_2022_12_31_07_09_1672513798 .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls -l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting additional feature extracted from finaladditionalfeaturefreq_2022_12_31_07_09_1672513798\n\ndbfile = open('finaladditionalfeaturefreq_2022_12_31_07_09_1672513798', 'rb') \nfinalfeature= pickle.load(dbfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbfile.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"additional_noise,additional_signal=finalfeature","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# working on signal data frame d2\n    \n    # adding and filling additional feature \"\"\" signal\"\"\" column in signal dataframe\nfor i in additional_signal:\n    if i in set(signalmaxfreq.keys()) and i not in set(noisemaxfreq.keys()):\n        dfx2[i]=1\n    elif i not in set(signalmaxfreq.keys()) and i in set(noisemaxfreq.keys()):\n        dfx2[i]=0\n    else:\n        dfx2[i]=-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# working on signal data frame d2\n        \n    # adding and filling additional feature \"\"\"noise\"\"\" column in signal dataframe d2\nfor i in additional_noise:\n    if i in set(noisemaxfreq.keys()) and i not in set(signalmaxfreq.keys()):\n        dfx2[i]=0\n    elif i not in set(noisemaxfreq.keys()) and i in set(signalmaxfreq.keys()):\n        dfx2[i]=1\n    else:\n        dfx2[i]=-1    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Working on noise data frame d1\n\n    #  adding and filling additional feature \"\"\"signal\"\"\" column in noise dataframe d1\nfor i in additional_signal:\n    if i in set(signalmaxfreq.keys()) and i not in set(noisemaxfreq.keys()):\n        dfx1[i]=0\n    elif i not in set(signalmaxfreq.keys()) and i in set(noisemaxfreq.keys()):\n        dfx1[i]=1\n    else:\n        dfx1[i]=-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Working on noise data frame d1\n    \n    #  adding and filling additional feature \"\"\"noise\"\"\" column in noise dataframe d1\nfor i in additional_noise:\n    if i in set(noisemaxfreq.keys()) and i not in set(signalmaxfreq.keys()):\n        dfx1[i]=1\n    elif i not in set(noisemaxfreq.keys()) and i in set(signalmaxfreq.keys()):\n        dfx1[i]=0\n    else:\n        dfx1[i]=-1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfx2['y']=1\ndfx1['y']=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfx3=dfx1.append(dfx2, ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test=dfx3['y']\nx_test=dfx3.drop(['y'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction using PERCEPTRON","metadata":{}},{"cell_type":"code","source":"#y_test_pred = ppn.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('Misclassified examples: %d' % (y_test != y_test_pred).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking loading of perceptron saved model\nload_ppn = open('/kaggle/working/perceptron_ppn-2023_01_01_12_30_1672576249', 'rb') \nload_model_ppn = pickle.load(load_ppn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_ppn.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred2 = load_model_ppn.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Misclassified count: %d' % (y_test != y_test_pred2).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using KNN","metadata":{}},{"cell_type":"code","source":"#from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classifier= KNeighborsClassifier(n_neighbors=4, metric='minkowski', p=2 )  \n#classifier.fit(x, y)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_knn= classifier.predict(x_test)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('Misclassified examples: %d' % (y_test != y_pred_knn).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"#from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#svm = SVC(kernel='linear', C=1.0, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#svm.fit(x, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_svm_pred=svm.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('Misclassified examples: %d' % (y_test != y_svm_pred).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving the svm model\n#!touch svm_model-`date +\"%Y_%m_%d_%I_%M_%s\"`","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ls -l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code for saving the perceptron model ppn\n    #svm_model_file = open('svm_model-2023_01_01_01_03_1672578238','ab')\n    #pickle.dump(svm,svm_model_file)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#svm_model_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the svm model\nload_svm = open('/kaggle/working/svm_model-2023_01_01_01_03_1672578238', 'rb') \nload_model_svm = pickle.load(load_svm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_svm.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_load_svm=load_model_svm.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Misclassified examples: %d' % (y_test != y_load_svm).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}